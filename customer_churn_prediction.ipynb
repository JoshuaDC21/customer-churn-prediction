{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation â€“ Telecom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Load datasets\n",
    "df_contract = pd.read_csv('/datasets/final_provider/contract.csv')\n",
    "df_personal = pd.read_csv('/datasets/final_provider/personal.csv')\n",
    "df_internet = pd.read_csv('/datasets/final_provider/internet.csv')\n",
    "df_phone = pd.read_csv('/datasets/final_provider/phone.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General view\n",
    "for name, df in zip(\n",
    "    [\"Contract\", \"Personal\", \"Internet\", \"Phone\"],\n",
    "    [df_contract, df_personal, df_internet, df_phone]\n",
    "):\n",
    "    print(f\"\\nðŸŸ© {name} - Shape: {df.shape}\")\n",
    "    display(df.head())\n",
    "    display(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_personal.merge(df_contract, on='customerID', how='left') \\\n",
    "                .merge(df_internet, on='customerID', how='left') \\\n",
    "                .merge(df_phone, on='customerID', how='left')\n",
    "\n",
    "print(f\"\\nðŸ“ Merged dataset: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate Values and Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "print(\"\\nðŸ” Missing values per column:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Duplicates\n",
    "print(\"\\nðŸ§¾ Duplicates:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary target column: 1 = churned, 0 = active\n",
    "df['churn'] = df['EndDate'].apply(lambda x: 0 if x == 'No' else 1)\n",
    "\n",
    "# Visualize distribution\n",
    "sns.countplot(x='churn', data=df)\n",
    "plt.title(\"Customer Churn Distribution\")\n",
    "plt.xlabel(\"Churn (1 = churned)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Proportion\n",
    "churn_rate = df['churn'].value_counts(normalize=True)\n",
    "print(\"\\nðŸ“Š Churn rate:\")\n",
    "print(churn_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical and numerical variables\n",
    "cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(\"\\nðŸ”¤ Categorical variables:\", cat_cols)\n",
    "print(\"\\nðŸ”¢ Numerical variables:\", num_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_fechas(df):\n",
    "    # Copy of dataframe\n",
    "    df = df.copy()\n",
    "\n",
    "    # Convert BeginDate to datetime\n",
    "    df['BeginDate'] = pd.to_datetime(df['BeginDate'])\n",
    "\n",
    "    # Convert EndDate to datetime, keeping \"No\" as NaT temporarily\n",
    "    df['EndDate'] = pd.to_datetime(df['EndDate'], errors='coerce')\n",
    "\n",
    "    # Replace NaT (the \"No\" values) with the maximum date in the dataset\n",
    "    fecha_referencia = df['EndDate'].max()\n",
    "    df['EndDate'] = df['EndDate'].fillna(fecha_referencia)\n",
    "\n",
    "    # Create tenure_days column\n",
    "    df['tenure_days'] = (df['EndDate'] - df['BeginDate']).dt.days\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = procesar_fechas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new column with the information about how long the customer has been subscribed to the service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new variable called num_servicios was created, which represents the total number of additional services contracted by each customer. This variable was derived from the optional services columns:\n",
    "\n",
    "- OnlineSecurity\n",
    "\n",
    "- OnlineBackup\n",
    "\n",
    "- DeviceProtection\n",
    "\n",
    "- TechSupport\n",
    "\n",
    "- StreamingTV\n",
    "\n",
    "- StreamingMovies\n",
    "\n",
    "The logic behind this transformation is that customers who subscribe to more services tend to be more engaged with the company, which could influence their decision to churn or not. Therefore, num_services can be a relevant predictive variable to improve the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of optional services columns\n",
    "servicios_cols = [\n",
    "    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "    'TechSupport', 'StreamingTV', 'StreamingMovies'\n",
    "]\n",
    "\n",
    "# Create the num_servicios variable by counting how many services are active per customer\n",
    "df['num_servicios'] = df[servicios_cols].apply(lambda row: sum(row == 'Yes'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Numerical Columns Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputar_y_convertir_numericas(df):\n",
    "    \"\"\"\n",
    "    Convert numerical types:\n",
    "    - float64 â†’ float32\n",
    "    - int64 â†’ int32\n",
    "    Also imputes the median if there are missing values.\n",
    "    \"\"\"\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        if df[col].isnull().any():\n",
    "            mediana = df[col].median()\n",
    "            df[col].fillna(mediana, inplace=True)\n",
    "\n",
    "        if df[col].dtype == 'float64':\n",
    "            df[col] = df[col].astype('float32')\n",
    "        elif df[col].dtype == 'int64':\n",
    "            df[col] = df[col].astype('int32')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Categorical Columns Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputar_servicios_especiales(df):\n",
    "    \"\"\"\n",
    "    Impute service columns with specific values:\n",
    "    - 'No Internet' for services that require a connection.\n",
    "    - 'No Phone' for multiple lines.\n",
    "    \"\"\"\n",
    "    # Services that require Internet\n",
    "    servicios_internet = [\n",
    "        'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
    "        'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies'\n",
    "    ]\n",
    "    \n",
    "    for col in servicios_internet:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col].fillna('No Internet', inplace=True)\n",
    "    \n",
    "    # Services that require a phone\n",
    "    if df['MultipleLines'].isnull().sum() > 0:\n",
    "        df['MultipleLines'].fillna('No Phone', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imputation\n",
    "df = imputar_y_convertir_numericas(df)\n",
    "df = imputar_servicios_especiales(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codificar_binarias(df):\n",
    "    \"\"\"\n",
    "    Detects binary columns and encodes them as 0 and 1.\n",
    "    Returns the modified DataFrame and a dictionary with the mappings used.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    mapeos = {}\n",
    "    \n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        valores = df[col].dropna().unique()\n",
    "        if len(valores) == 2:\n",
    "            # Create a smart mapping if possible\n",
    "            if 'No' in valores and 'Yes' in valores:\n",
    "                mapeo = {'No': 0, 'Yes': 1}\n",
    "            elif 'Female' in valores and 'Male' in valores:\n",
    "                mapeo = {'Female': 0, 'Male': 1}\n",
    "            else:\n",
    "                mapeo = {valores[0]: 0, valores[1]: 1}\n",
    "\n",
    "            df[col] = df[col].map(mapeo)\n",
    "            mapeos[col] = mapeo\n",
    "    \n",
    "    return df, mapeos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, mapeos_binarias = codificar_binarias(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, mapeo in mapeos_binarias.items():\n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"  Applied Mapping: {mapeo}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'customerID'\n",
    "df = df.drop(columns=['customerID'])\n",
    "\n",
    "# Drop datetime columns\n",
    "datetime_cols = df.select_dtypes(include=['datetime64']).columns\n",
    "df = df.drop(columns=datetime_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns with more than two classes (excluding ID)\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "multiclase_cols = [col for col in cat_cols if df[col].nunique() > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the encoded columns\n",
    "print(\"Columns encoded with One-Hot Encoding:\")\n",
    "for col in multiclase_cols:\n",
    "    print(f\"- {col} ({df[col].nunique()} classes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply OHE and store the number of new columns\n",
    "df_encoded = pd.get_dummies(df, columns=multiclase_cols, drop_first=True)\n",
    "\n",
    "# Calculate how many new columns were generated\n",
    "n_new_columns = df_encoded.shape[1] - df.shape[1] + len(multiclase_cols)\n",
    "print(f\"\\n{n_new_columns} new columns were generated with One-Hot Encoding.\")\n",
    "\n",
    "# Replace df with the new encoded DataFrame\n",
    "df = df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = (df['churn'] == 0).sum()\n",
    "pos = (df['churn'] == 1).sum()\n",
    "weight_for_1 = neg / pos\n",
    "\n",
    "print(weight_for_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a clear class imbalance, which we will need to address, but it will be handled through the parameters of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['churn'])\n",
    "y = df['churn']\n",
    "\n",
    "# First split into training (70%) and temporary (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=42)\n",
    "\n",
    "# Then split the temporary set into validation (15%) and test (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42)\n",
    "\n",
    "print(f\"Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Numerical variables to scale\n",
    "num_vars = ['MonthlyCharges', 'TotalCharges', 'tenure_days', 'num_servicios']\n",
    "\n",
    "# Copy to avoid views\n",
    "X_train = X_train.copy()\n",
    "X_val = X_val.copy()\n",
    "X_test = X_test.copy()\n",
    "\n",
    "# Create the scaler and fit it only on the training data\n",
    "scaler = MinMaxScaler()\n",
    "X_train.loc[:, num_vars] = scaler.fit_transform(X_train[num_vars])\n",
    "\n",
    "# Apply the transformation to validation and test sets\n",
    "X_val.loc[:, num_vars] = scaler.transform(X_val[num_vars])\n",
    "X_test.loc[:, num_vars] = scaler.transform(X_test[num_vars])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "def train_model(model, X_train, y_train, class_weight=None, epochs=50, batch_size=64, verbose=0, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a model and measures training time.\n",
    "    For sklearn, XGBoost, LightGBM, or Keras models.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: model to train\n",
    "    - X_train, y_train: training data\n",
    "    - class_weight: dictionary of class weights (used in sklearn and keras)\n",
    "    - epochs, batch_size, verbose: used for Keras\n",
    "    - kwargs: additional parameters for .fit() if applicable\n",
    "    \n",
    "    Returns:\n",
    "    - trained model\n",
    "    - training time in seconds (float)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Detect if it is a Keras model\n",
    "    if hasattr(model, \"fit\") and hasattr(model.fit, \"__call__\") and 'keras' in str(type(model)).lower():\n",
    "        # For Keras model\n",
    "        model.fit(X_train, y_train,\n",
    "                  class_weight=class_weight,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=verbose,\n",
    "                  validation_split=0,  # Do not use validation here, external val set is passed\n",
    "                  **kwargs)\n",
    "    else:\n",
    "        # sklearn, xgboost, or lightgbm models\n",
    "        try:\n",
    "            model.fit(X_train, y_train, class_weight=class_weight, **kwargs)\n",
    "        except TypeError:\n",
    "            # Some models do not support class_weight\n",
    "            model.fit(X_train, y_train, **kwargs)\n",
    "            \n",
    "    training_time = time.time() - start_time\n",
    "    return model, training_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y_true, batch_size=64):\n",
    "    \"\"\"\n",
    "    Evaluates the model on X data with true labels y_true.\n",
    "    For sklearn, xgboost, lightgbm, or keras models.\n",
    "    Returns a dictionary with metrics (AUC-ROC, Accuracy).\n",
    "    \"\"\"\n",
    "    # Detect if it is a Keras model\n",
    "    if hasattr(model, \"predict\") and 'keras' in str(type(model)).lower():\n",
    "        y_pred_proba = model.predict(X, batch_size=batch_size).flatten()\n",
    "        y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "    else:\n",
    "        y_pred_proba = model.predict_proba(X)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "        y_pred = model.predict(X)\n",
    "    \n",
    "    auc = roc_auc_score(y_true, y_pred_proba) if y_pred_proba is not None else None\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return {'AUC-ROC': auc, 'Accuracy': acc}\n",
    "\n",
    "results = {\n",
    "    \"model_name\": [],\n",
    "    \"dataset\": [],  # 'validation' or 'test'\n",
    "    \"AUC-ROC\": [],\n",
    "    \"Accuracy\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_model = LogisticRegression(\n",
    "    solver='liblinear',     \n",
    "    class_weight='balanced', \n",
    "    random_state=42,\n",
    "    max_iter=500             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and capture time\n",
    "logreg_model, logreg_training_time = train_model(logreg_model, X_train, y_train)\n",
    "\n",
    "# Evaluation on validation and test sets\n",
    "logreg_val_metrics = evaluate_model(logreg_model, X_val, y_val)\n",
    "logreg_test_metrics = evaluate_model(logreg_model, X_test, y_test)\n",
    "\n",
    "# Display results\n",
    "print(\"Logistic Regression - Validation:\", logreg_val_metrics)\n",
    "print(\"Logistic Regression - Test:\", logreg_test_metrics)\n",
    "print(f\"Training time: {logreg_training_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate the model with initial parameters\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and capture time\n",
    "rf_model, rf_training_time = train_model(rf_model, X_train, y_train)\n",
    "\n",
    "# Evaluation on validation and test sets\n",
    "rf_val_metrics = evaluate_model(rf_model, X_val, y_val)\n",
    "rf_test_metrics = evaluate_model(rf_model, X_test, y_test)\n",
    "\n",
    "# Display results\n",
    "print(\"Random Forest - Validation:\", rf_val_metrics)\n",
    "print(\"Random Forest - Test:\", rf_test_metrics)\n",
    "print(f\"Random Forest training time: {rf_training_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initialize XGBoost model with basic parameters and class balancing\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),  # class balancing\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and measure time\n",
    "xgb_model, xgb_training_time = train_model(xgb_model, X_train, y_train)\n",
    "\n",
    "# Evaluate on validation and test sets\n",
    "xgb_val_metrics = evaluate_model(xgb_model, X_val, y_val)\n",
    "xgb_test_metrics = evaluate_model(xgb_model, X_test, y_test)\n",
    "\n",
    "# Display results\n",
    "print(\"XGBoost - Validation:\", xgb_val_metrics)\n",
    "print(\"XGBoost - Test:\", xgb_test_metrics)\n",
    "print(f\"XGBoost training time: {xgb_training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Initialize LightGBM model with basic parameters and class balancing\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and measure time\n",
    "lgb_model, lgb_training_time = train_model(lgb_model, X_train, y_train)\n",
    "\n",
    "# Evaluate on validation and test sets\n",
    "lgb_val_metrics = evaluate_model(lgb_model, X_val, y_val)\n",
    "lgb_test_metrics = evaluate_model(lgb_model, X_test, y_test)\n",
    "\n",
    "# Display results\n",
    "print(\"LightGBM - Validation:\", lgb_val_metrics)\n",
    "print(\"LightGBM - Test:\", lgb_test_metrics)\n",
    "print(f\"LightGBM training time: {lgb_training_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define a simple architecture for binary classification\n",
    "def build_nn_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "nn_model = build_nn_model(X_train.shape[1])\n",
    "\n",
    "# Compute class weights for balancing (optional)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=np.unique(y_train),\n",
    "                                     y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Train neural network and measure time\n",
    "nn_model, nn_training_time = train_model(\n",
    "    nn_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    class_weight=class_weight_dict,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Evaluate on validation and test sets\n",
    "nn_val_metrics = evaluate_model(nn_model, X_val, y_val)\n",
    "nn_test_metrics = evaluate_model(nn_model, X_test, y_test)\n",
    "\n",
    "# Display results\n",
    "print(\"Neural Network - Validation:\", nn_val_metrics)\n",
    "print(\"Neural Network - Test:\", nn_test_metrics)\n",
    "print(f\"Neural Network training time: {nn_training_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": \"Logistic Regression\",\n",
    "        \"AUC-ROC Validation\": logreg_val_metrics['AUC-ROC'],\n",
    "        \"Accuracy Validation\": logreg_val_metrics['Accuracy'],\n",
    "        \"AUC-ROC Test\": logreg_test_metrics['AUC-ROC'],\n",
    "        \"Accuracy Test\": logreg_test_metrics['Accuracy'],\n",
    "        \"Time (s)\": logreg_training_time\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Random Forest\",\n",
    "        \"AUC-ROC Validation\": rf_val_metrics['AUC-ROC'],\n",
    "        \"Accuracy Validation\": rf_val_metrics['Accuracy'],\n",
    "        \"AUC-ROC Test\": rf_test_metrics['AUC-ROC'],\n",
    "        \"Accuracy Test\": rf_test_metrics['Accuracy'],\n",
    "        \"Time (s)\": rf_training_time\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"XGBoost\",\n",
    "        \"AUC-ROC Validation\": xgb_val_metrics['AUC-ROC'],\n",
    "        \"Accuracy Validation\": xgb_val_metrics['Accuracy'],\n",
    "        \"AUC-ROC Test\": xgb_test_metrics['AUC-ROC'],\n",
    "        \"Accuracy Test\": xgb_test_metrics['Accuracy'],\n",
    "        \"Time (s)\": xgb_training_time\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"LightGBM\",\n",
    "        \"AUC-ROC Validation\": lgb_val_metrics['AUC-ROC'],\n",
    "        \"Accuracy Validation\": lgb_val_metrics['Accuracy'],\n",
    "        \"AUC-ROC Test\": lgb_test_metrics['AUC-ROC'],\n",
    "        \"Accuracy Test\": lgb_test_metrics['Accuracy'],\n",
    "        \"Time (s)\": lgb_training_time\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Neural Network\",\n",
    "        \"AUC-ROC Validation\": nn_val_metrics['AUC-ROC'],\n",
    "        \"Accuracy Validation\": nn_val_metrics['Accuracy'],\n",
    "        \"AUC-ROC Test\": nn_test_metrics['AUC-ROC'],\n",
    "        \"Accuracy Test\": nn_test_metrics['Accuracy'],\n",
    "        \"Time (s)\": nn_training_time\n",
    "    }\n",
    "])\n",
    "\n",
    "# Display table sorted by Test AUC-ROC\n",
    "results_df_sorted = results_df.sort_values(by=\"AUC-ROC Test\", ascending=False)\n",
    "display(results_df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five supervised models were compared to predict customer churn. The metrics used were AUC-ROC (primary), Accuracy (secondary), and Training Time.\n",
    "\n",
    "### 1. Primary Metric: AUC-ROC\n",
    "\n",
    "AUC-ROC measures the model's ability to distinguish between customers who churn and those who do not. Values closer to 1 are better.\n",
    "\n",
    "| Model               | Test AUC-ROC   |\n",
    "|---------------------|----------------|\n",
    "| **XGBoost**         | **0.8916**   \n",
    "| LightGBM            | 0.8819  \n",
    "| Random Forest       | 0.8563  \n",
    "| Red Neuronal        | 0.8391  \n",
    "| RegresiÃ³n LogÃ­stica | 0.8375  \n",
    "\n",
    "> **XGBoost** demonstrates the best performance for this metric, showing excellent classification capability.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Secondary Metric: Accuracy\n",
    "\n",
    "Accuracy measures the proportion of correct predictions. It does not account for class imbalance but provides a general view of performance.\n",
    "\n",
    "| Model               | Test Accuracy   |\n",
    "|---------------------|-----------------|\n",
    "| **XGBoost**         | **0.8411**   \n",
    "| LightGBM            | 0.8174  \n",
    "| Random Forest       | 0.8127  \n",
    "| RegresiÃ³n LogÃ­stica | 0.7512  \n",
    "| Red Neuronal        | 0.7294  \n",
    "\n",
    ">  **XGBoost** also leads in this metric, confirming its robustness.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Training Time\n",
    "\n",
    "Time required to train each model was measured.\n",
    "\n",
    "| Model               | Time(s)    |\n",
    "|---------------------|------------|\n",
    "| **RegresiÃ³n LogÃ­stica** | **0.014**   \n",
    "| LightGBM            | 0.166  \n",
    "| Random Forest       | 0.320  \n",
    "| XGBoost             | 1.276  \n",
    "| Red Neuronal        | 3.566  \n",
    "\n",
    ">  **The neural network was the slowest,**, while **LightGBM** offers a good balance between speed and performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "| Criterion             | Best Model | Comment                                                                 |\n",
    "|-----------------------|----------------|---------------------------------------------------------------------------|\n",
    "| Best AUC-ROC        | **XGBoost**    | Highest predictive capability                                             |\n",
    "| Speed               | LogReg         | Very fast, but lower performance                                          |\n",
    "| Overall Balance     | LightGBM       | Combines reasonable accuracy with computational efficiency                |\n",
    "\n",
    "---\n",
    "\n",
    "### Recommendation\n",
    "\n",
    "- For **maximum accuracy**, use **XGBoost**.\n",
    "- For **efficiency with good performance**, **LightGBM** is an excellent alternative.\n",
    "- The **neural network** and **logistic regression** can be excluded in this case due to lower performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The objective of this project was to develop models capable of predicting **customer churn** using historical data from a telecommunications company. Five supervised models were implemented: **Logistic Regression**, **Random Forest**, **XGBoost**, **LightGBM**, and a **Simple Neural Network**.\n",
    "\n",
    "### Accuracy vs Interpretability\n",
    "\n",
    "Although complex models like **XGBoost** and **LightGBM** provided the best results in terms of **AUC-ROC** and **accuracy**, the **balance between precision and explainability** should be considered:\n",
    "\n",
    "- **XGBoost** achieved the highest predictive performance (AUC-ROC = 0.89), making it the most effective model if accuracy is the primary goal.  \n",
    "- **LightGBM**, with similar metrics and significantly lower training time, represents a more efficient alternative suitable for production when computational cost is a concern.  \n",
    "- **Logistic Regression**, while less accurate, provides **maximum interpretability**, which is essential if predictions must be translated into business decisions or justified to stakeholders.\n",
    "\n",
    "### Interpretability as a Business Criterion\n",
    "\n",
    "According to reviewer recommendations, in real-world problems like this, where decisions must be understandable to business areas and justify retention campaigns, **model interpretability is critical**. Therefore:\n",
    "\n",
    "- It is recommended to **start with interpretable models** (such as logistic regression or decision trees) to generate a comprehensible foundation of churn behavior.  \n",
    "- **Complex models** like XGBoost or neural networks should only be used **if there is a significant performance improvement** that justifies the loss of transparency.\n",
    "\n",
    "### Final Recommendation\n",
    "\n",
    "- For an **analytical or exploratory environment**, use **Logistic Regression** or **Random Forest** to facilitate interpretation and insights extraction.  \n",
    "- For an **operational or competitive environment**, where maximum precision is required, use **XGBoost** with interpretability tools like **SHAP** to explain predictions.\n",
    "\n",
    "---\n",
    "\n",
    "This balanced approach ensures both **predictive effectiveness** and **practical usability** in real business contexts.\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
